resummarize_end_data <- TRUE
# reprocess_task_data <- FALSE
# reprocess_ehi_data <- FALSE
# reprocess_demographics_data <-FALSE
# reprocess_end_data <- FALSE
#
# resummarize_task_data <- FALSE
# resummarize_ehi_data <- FALSE
# resummarize_demographics_data <- FALSE
# resummarize_end_data <- FALSE
# Chunk 4: load_process_task
data_dir <- here::here("data")
input_dir <- here::here(data_dir, "input_0pt6")
proc_dir <- here::here(data_dir, "proc_0pt6")
## If data have been processed already, set to FALSE
if (reprocess_task_data == TRUE) {
load_and_process(input_dir, proc_dir, data_type = "task")
}
# Chunk 5: load_process_surveys
if (reprocess_ehi_data == TRUE) {
load_and_process(input_dir, proc_dir, data_type = "ehi")
}
#TODO: Process demographic, end question data
if (reprocess_demographics_data == TRUE) {
load_and_process(input_dir, proc_dir, data_type = "demographics")
}
if (reprocess_end_data == TRUE) {
load_and_process(input_dir, proc_dir, data_type = "end")
}
# Chunk 6: debug_survey
## For testing: step through load_and_process for an individual input file
#  data_type <- "demographics"
#  input_files <- get_input_paths(input_dir, data_type)
#
# input_dir
#
# input_files
# n_input_files <- length(input_files)
# n_input_files
# input_path <- input_files[7] ## This will be in s a loop
# input_path
# data_raw <- load_raw(input_path, data_type)
# data_raw
# subject_id <- data_raw$subject %>% first() %>% as.character()
# subject_id
# data_raw
# data_recoded <- recode_raw(data_raw, data_type)
# data_recoded
# data_cleaned <- clean_recoded(data_recoded, data_type)
# data_cleaned
# data_tests(data_cleaned, data_type)
# save_cleaned(data_cleaned, proc_dir, data_type)
# Chunk 7: calculate_variables
## Load processed data
ind_input_dir <- here(proc_dir, "individual")
summary_output_dir <- here(proc_dir, "summary")
## Create summary row for each subject
## TODO: Add overall median RT to summary spreadsheet
if (resummarize_task_data == TRUE) {
## Create summarized task data (saves to tsv as a side effect)
task_summary <-
load_and_summarize_proc(ind_input_dir, summary_output_dir,
data_type = "task")
}
if (resummarize_ehi_data == TRUE) {
## Create summarized task data (saves to tsv as a side effect)
ehi_summary <-
load_and_summarize_proc(ind_input_dir, summary_output_dir,
data_type = "ehi")
}
## TODO: (URGENT) fix logic for race variable -- always shows "multiple"
if (resummarize_demographics_data == TRUE) {
## Create summarized demographics data (saves to tsv as a side effect)
demo_summary <-
load_and_summarize_proc(ind_input_dir, summary_output_dir,
data_type = "demographics")
}
if (resummarize_end_data == TRUE) {
## Create summarized end question data (saves to tsv as a side effect)
end_summary <-
load_and_summarize_proc(ind_input_dir, summary_output_dir,
data_type = "end")
}
# Chunk 8: debug_summary
# group_summary <- tibble(
#   subject = as.character(),
#   ehi_i1_writing = as.numeric(),
#   ehi_i2_throwing = as.numeric(),
#   ehi_i3_toothbrush = as.numeric(),
#   ehi_i4_spoon = as.numeric(),
#   ehi_total = as.numeric()
# )
#
#
# group_summary <- tibble(
#   subject = as.character(),
#   age = as.numeric(),
#   country = as.character(),
#   sex = as.character(),
#   education = as.character(),
#   race = as.character(),
#   hispanic_ethnicity = as.character()
# )
#
# group_summary <- tibble(
#   subject = as.character(),
#   task_experience_response = as.character(),
#   task_experience_other_response = as.character(),
#   open_ended_feedback_response = as.character()
# )
#
# group_summary <- tibble(
#   subject = as.character(),
#   first_block = as.character(),
#   acc_slash = as.numeric(),
#   acc_z = as.numeric(),
#   acc_absent_slash = as.numeric(),
#   acc_present_slash = as.numeric(),
#   acc_absent_z = as.numeric(),
#   acc_present_z = as.numeric(),
#   acc_global_LVF = as.numeric(),
#   acc_global_RVF = as.numeric(),
#   acc_local_LVF = as.numeric(),
#   acc_local_RVF = as.numeric(),
#   rt_global_LVF = as.numeric(),
#   rt_global_RVF = as.numeric(),
#   rt_local_LVF = as.numeric(),
#   rt_local_RVF = as.numeric(),
#   exclude_many_gos = as.logical(),
#   exclude_low_acc = as.logical(),
#   exclude_low_rt = as.logical(),
#   exclude_high_rt = as.logical(),
#   exclude = as.logical()
# )
#
# data_type = "task"
# input_files <- get_input_paths(ind_input_dir, data_type = data_type,
#                                pattern = "*.tsv")
#
# input_path <- input_files[1]
# input_path
# data_proc <- load_proc(input_path, data_type = data_type)
# data_proc
# ind_summary <- summarize_ind(data_proc, data_type = data_type)
# ind_summary
#
# group_summary <- group_summary %>% add_row(ind_summary)
# group_summary
# Chunk 9: combine
## Combine summaries into one big table, with a wide row for each subject.
summary <- task_summary %>%
left_join(ehi_summary) %>%
left_join(demo_summary) %>%
left_join(end_summary)
write_tsv(summary, here::here(summary_output_dir, "summary.tsv"))
# Chunk 10: analyze_rt
## Reaction time analyses
# Chunk 11: report_rt
## Visualize per-trial RT data (make absent one color, present another)
## Report RT data by condition
# Chunk 12: report_acc
## Report accuracy data by condition
# Chunk 13: report_duration
## Report experiment duration
# Chunk 14: report_demographics
## Summarize demographic data
## And "end question" responses
# Chunk 15
## Create individual summary data
## Add to a summary spreadsheet
data_proc
## For testing: step through load_and_process for an individual input file
data_type <- "task"
input_files <- get_input_paths(input_dir, data_type)
input_dir
input_files
n_input_files <- length(input_files)
n_input_files
input_path <- input_files[7] ## This will be in s a loop
input_path
input_path <- input_files[1] ## This will be in s a loop
input_path
data_raw <- load_raw(input_path, data_type)
data_raw
data_raw
subject_id <- data_raw$subject %>% first() %>% as.character()
subject_id
data_raw
data_recoded <- recode_raw(data_raw, data_type)
data_recoded
data_cleaned <- clean_recoded(data_recoded, data_type)
data_cleaned
data_tests(data_cleaned, data_type)
#   hispanic_ethnicity = as.character()
# )
#
# group_summary <- tibble(
#   subject = as.character(),
#   task_experience_response = as.character(),
#   task_experience_other_response = as.character(),
#   open_ended_feedback_response = as.character()
# )
#
group_summary <- tibble(
subject = as.character(),
first_block = as.character(),
acc_slash = as.numeric(),
acc_z = as.numeric(),
acc_absent_slash = as.numeric(),
acc_present_slash = as.numeric(),
acc_absent_z = as.numeric(),
acc_present_z = as.numeric(),
acc_global_LVF = as.numeric(),
acc_global_RVF = as.numeric(),
acc_local_LVF = as.numeric(),
acc_local_RVF = as.numeric(),
rt_global_LVF = as.numeric(),
rt_global_RVF = as.numeric(),
rt_local_LVF = as.numeric(),
rt_local_RVF = as.numeric(),
exclude_many_gos = as.logical(),
exclude_low_acc = as.logical(),
exclude_low_rt = as.logical(),
exclude_high_rt = as.logical(),
exclude = as.logical()
)
#   hispanic_ethnicity = as.character()
# )
#
# group_summary <- tibble(
#   subject = as.character(),
#   task_experience_response = as.character(),
#   task_experience_other_response = as.character(),
#   open_ended_feedback_response = as.character()
# )
#
group_summary <- tibble(
subject = as.character(),
first_block = as.character(),
acc_slash = as.numeric(),
acc_z = as.numeric(),
acc_absent = as.numeric(),
acc_present = as.numeric(),
acc_global_LVF = as.numeric(),
acc_global_RVF = as.numeric(),
acc_local_LVF = as.numeric(),
acc_local_RVF = as.numeric(),
rt_global_LVF = as.numeric(),
rt_global_RVF = as.numeric(),
rt_local_LVF = as.numeric(),
rt_local_RVF = as.numeric(),
exclude_many_gos = as.logical(),
exclude_low_acc = as.logical(),
exclude_low_rt = as.logical(),
exclude_high_rt = as.logical(),
exclude = as.logical()
)
data_type = "task"
input_files <- get_input_paths(ind_input_dir, data_type = data_type,
pattern = "*.tsv")
input_path <- input_files[1]
input_path
data_proc <- load_proc(input_path, data_type = data_type)
data_proc
ind_proc
ind_proc <- load_proc(input_path, data_type = data_type)
ind_proc
subject_id <-
ind_proc$subject %>% first() %>% as.character()
source("~/proj/navon/analysis/lib/load_process/load_process.R")
#### Accuracy
## Calculate percent correct for each block,
## separating present and absent trials
ind_proc <- ind_proc %>%
mutate(response_log = case_when(response == "absent" ~ 0,
response == "present" ~ 1)) %>%
filter(block_type == "main")
ind_proc
response_counts_pa <- ind_proc %>%
group_by(target_present, subject) %>%
summarize(
total_responses = n(),
n_present_resp = sum(response_log),
n_absent_resp = total_responses - n_present_resp,
n_correct = sum(correct),
percent_correct = 100 * (n_correct / total_responses)
)
acc_pa <- response_counts_pa %>%
ungroup() %>%
mutate(target_present = target_present %>% recode("no" = "absent", yes = "present")) %>%
select(subject, target_present, percent_correct) %>%
pivot_wider(
names_from = c(target_present),
names_prefix = "acc_",
values_from = percent_correct
)
ind_summary <- acc_pa
## Calculate percent correct for each block,
## collapsing present and absent trials
response_counts_block <- ind_proc %>%
group_by(block_response, subject) %>%
summarize(
total_responses = n(),
n_present_resp = sum(response_log),
n_absent_resp = total_responses - n_present_resp,
n_correct = sum(correct),
percent_correct = 100 * (n_correct / total_responses)
)
acc_all <- response_counts_block %>%
ungroup() %>%
select(subject, block_response, percent_correct) %>%
pivot_wider(
names_from = block_response,
names_prefix = "acc_",
values_from = percent_correct
)
ind_summary <- left_join(acc_all, ind_summary)
ind_proc
ind_proc %>% slice(1)
ind_proc %>% slice(1) %>% .[["block_response"]]
source("~/proj/navon/analysis/lib/load_process/load_process.R")
# Chunk 1: setup
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE,
fig.align = "center", fig.width = 9,
fig.height = 6, results = "asis")
options(knitr.kable.NA = "")
cli.progress_show_after <- 0
# Suppress summarise info
options(dplyr.summarise.inform = FALSE)
# Chunk 2: lib
library(here)
library(readr)
library(dplyr)
library(tidyr)
library(stringr)
library(cli) # For printing error messages
library(glue) # To make writing error message strings easier
source(here::here("lib", "load_process", "load_process.R"))
# Chunk 3: config
reprocess_task_data <- TRUE
reprocess_ehi_data <- TRUE
reprocess_demographics_data <- TRUE
reprocess_end_data <- TRUE
resummarize_task_data <- TRUE
resummarize_ehi_data <- TRUE
resummarize_demographics_data <- TRUE
resummarize_end_data <- TRUE
# reprocess_task_data <- FALSE
# reprocess_ehi_data <- FALSE
# reprocess_demographics_data <-FALSE
# reprocess_end_data <- FALSE
#
# resummarize_task_data <- FALSE
# resummarize_ehi_data <- FALSE
# resummarize_demographics_data <- FALSE
# resummarize_end_data <- FALSE
# Chunk 4: load_process_task
data_dir <- here::here("data")
input_dir <- here::here(data_dir, "input_0pt6")
proc_dir <- here::here(data_dir, "proc_0pt6")
## If data have been processed already, set to FALSE
if (reprocess_task_data == TRUE) {
load_and_process(input_dir, proc_dir, data_type = "task")
}
# Chunk 5: load_process_surveys
if (reprocess_ehi_data == TRUE) {
load_and_process(input_dir, proc_dir, data_type = "ehi")
}
#TODO: Process demographic, end question data
if (reprocess_demographics_data == TRUE) {
load_and_process(input_dir, proc_dir, data_type = "demographics")
}
if (reprocess_end_data == TRUE) {
load_and_process(input_dir, proc_dir, data_type = "end")
}
# Chunk 6: debug_survey
## For testing: step through load_and_process for an individual input file
data_type <- "task"
input_files <- get_input_paths(input_dir, data_type)
input_dir
input_files
n_input_files <- length(input_files)
n_input_files
input_path <- input_files[1] ## This will be in s a loop
input_path
data_raw <- load_raw(input_path, data_type)
data_raw
subject_id <- data_raw$subject %>% first() %>% as.character()
subject_id
data_raw
data_recoded <- recode_raw(data_raw, data_type)
data_recoded
data_cleaned <- clean_recoded(data_recoded, data_type)
data_cleaned
data_tests(data_cleaned, data_type)
save_cleaned(data_cleaned, proc_dir, data_type)
# Chunk 7: calculate_variables
## Load processed data
ind_input_dir <- here(proc_dir, "individual")
summary_output_dir <- here(proc_dir, "summary")
## Create summary row for each subject
## TODO: Add overall median RT to summary spreadsheet
if (resummarize_task_data == TRUE) {
## Create summarized task data (saves to tsv as a side effect)
task_summary <-
load_and_summarize_proc(ind_input_dir, summary_output_dir,
data_type = "task")
}
if (resummarize_ehi_data == TRUE) {
## Create summarized task data (saves to tsv as a side effect)
ehi_summary <-
load_and_summarize_proc(ind_input_dir, summary_output_dir,
data_type = "ehi")
}
## TODO: (URGENT) fix logic for race variable -- always shows "multiple"
if (resummarize_demographics_data == TRUE) {
## Create summarized demographics data (saves to tsv as a side effect)
demo_summary <-
load_and_summarize_proc(ind_input_dir, summary_output_dir,
data_type = "demographics")
}
if (resummarize_end_data == TRUE) {
## Create summarized end question data (saves to tsv as a side effect)
end_summary <-
load_and_summarize_proc(ind_input_dir, summary_output_dir,
data_type = "end")
}
# Chunk 8: debug_summary
# group_summary <- tibble(
#   subject = as.character(),
#   ehi_i1_writing = as.numeric(),
#   ehi_i2_throwing = as.numeric(),
#   ehi_i3_toothbrush = as.numeric(),
#   ehi_i4_spoon = as.numeric(),
#   ehi_total = as.numeric()
# )
#
#
# group_summary <- tibble(
#   subject = as.character(),
#   age = as.numeric(),
#   country = as.character(),
#   sex = as.character(),
#   education = as.character(),
#   race = as.character(),
#   hispanic_ethnicity = as.character()
# )
#
# group_summary <- tibble(
#   subject = as.character(),
#   task_experience_response = as.character(),
#   task_experience_other_response = as.character(),
#   open_ended_feedback_response = as.character()
# )
#
# group_summary <- tibble(
#   subject = as.character(),
#   first_block = as.character(),
#   acc_slash = as.numeric(),
#   acc_z = as.numeric(),
#   acc_absent = as.numeric(),
#   acc_present = as.numeric(),
#   acc_global_LVF = as.numeric(),
#   acc_global_RVF = as.numeric(),
#   acc_local_LVF = as.numeric(),
#   acc_local_RVF = as.numeric(),
#   rt_global_LVF = as.numeric(),
#   rt_global_RVF = as.numeric(),
#   rt_local_LVF = as.numeric(),
#   rt_local_RVF = as.numeric(),
#   exclude_many_gos = as.logical(),
#   exclude_low_acc = as.logical(),
#   exclude_low_rt = as.logical(),
#   exclude_high_rt = as.logical(),
#   exclude = as.logical()
# )
#
# data_type = "task"
# input_files <- get_input_paths(ind_input_dir, data_type = data_type,
#                                pattern = "*.tsv")
#
# input_path <- input_files[1]
# input_path
# ind_proc <- load_proc(input_path, data_type = data_type)
# ind_proc
# ind_summary <- summarize_ind(ind_proc, data_type = data_type)
# ind_summary
#
# group_summary <- group_summary %>% add_row(ind_summary)
# group_summary
# Chunk 9: combine
## Combine summaries into one big table, with a wide row for each subject.
summary <- task_summary %>%
left_join(ehi_summary) %>%
left_join(demo_summary) %>%
left_join(end_summary)
write_tsv(summary, here::here(summary_output_dir, "summary.tsv"))
# Chunk 10: analyze_rt
## Reaction time analyses
# Chunk 11: report_rt
## Visualize per-trial RT data (make absent one color, present another)
## Report RT data by condition
# Chunk 12: report_acc
## Report accuracy data by condition
# Chunk 13: report_duration
## Report experiment duration
# Chunk 14: report_demographics
## Summarize demographic data
## And "end question" responses
# Chunk 15
## Create individual summary data
## Add to a summary spreadsheet
