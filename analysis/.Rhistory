end_time <- last(ind_proc$time_elapsed_ms)
end_time
end_time - start_time
duration_s <- duration_ms*1000
duration_ms <- end_time - start_time
duration_s <- duration_ms*1000
duration_s
duration_s <- duration_ms/1000
duration_s
353/60
duration_ms <- end_time
duration_s <- duration_ms/1000
duration_s
416/60
duration_s <- last(ind_proc$time_elapsed_ms) / 1000
duration_s
source("~/proj/navon/analysis/lib/load_process/load_process.R")
source("~/proj/navon/analysis/lib/load_process/load_process.R")
# Chunk 1: setup
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE,
fig.align = "center", fig.width = 9,
fig.height = 6, results = "asis")
options(knitr.kable.NA = "")
cli.progress_show_after <- 0
# Suppress summarise info
options(dplyr.summarise.inform = FALSE)
# Chunk 2: lib
library(here)
library(readr)
library(dplyr)
library(tidyr)
library(stringr)
library(cli) # For printing error messages
library(glue) # To make writing error message strings easier
source(here::here("lib", "load_process", "load_process.R"))
# Chunk 3: config
reprocess_task_data <- TRUE
reprocess_ehi_data <- TRUE
reprocess_demographics_data <- TRUE
reprocess_end_data <- TRUE
resummarize_task_data <- TRUE
resummarize_ehi_data <- TRUE
resummarize_demographics_data <- TRUE
resummarize_end_data <- TRUE
# reprocess_task_data <- FALSE
# reprocess_ehi_data <- FALSE
# reprocess_demographics_data <-FALSE
# reprocess_end_data <- FALSE
#
# resummarize_task_data <- FALSE
# resummarize_ehi_data <- FALSE
# resummarize_demographics_data <- FALSE
# resummarize_end_data <- FALSE
# Chunk 4: load_process_task
data_dir <- here::here("data")
input_dir <- here::here(data_dir, "input_prepilot")
proc_dir <- here::here(data_dir, "proc_prepilot")
## If data have been processed already, set to FALSE
if (reprocess_task_data == TRUE) {
load_and_process(input_dir, proc_dir, data_type = "task")
}
# Chunk 5: load_process_surveys
if (reprocess_ehi_data == TRUE) {
load_and_process(input_dir, proc_dir, data_type = "ehi")
}
#TODO: Process demographic, end question data
if (reprocess_demographics_data == TRUE) {
load_and_process(input_dir, proc_dir, data_type = "demographics")
}
if (reprocess_end_data == TRUE) {
load_and_process(input_dir, proc_dir, data_type = "end")
}
# Chunk 6: debug_survey
## For testing: step through load_and_process for an individual input file
#  data_type <- "task"
#  input_files <- get_input_paths(input_dir, data_type)
#
# input_dir
#
# input_files
# n_input_files <- length(input_files)
# n_input_files
# input_path <- input_files[1] ## This will be in s a loop
# input_path
# data_raw <- load_raw(input_path, data_type)
# data_raw
# subject_id <- data_raw$subject %>% first() %>% as.character()
# subject_id
# data_raw
# data_recoded <- recode_raw(data_raw, data_type)
# data_recoded
# data_cleaned <- clean_recoded(data_recoded, data_type)
# data_cleaned
# data_tests(data_cleaned, data_type)
# save_cleaned(data_cleaned, proc_dir, data_type)
# Chunk 7: calculate_variables
## Load processed data
ind_input_dir <- here(proc_dir, "individual")
summary_output_dir <- here(proc_dir, "summary")
## Create summary row for each subject
## TODO: Add overall median RT to summary spreadsheet
if (resummarize_task_data == TRUE) {
## Create summarized task data (saves to tsv as a side effect)
task_summary <-
load_and_summarize_proc(ind_input_dir, summary_output_dir,
data_type = "task")
}
ind_summary
ind_summary %>%
mutate(duration_s = last(ind_proc$time_elapsed_ms) / 1000)
ind_summary %>%
mutate(duration_poop = last(ind_proc$time_elapsed_ms) / 1000)
ind_summary %>%
mutate(duration_poop = last(ind_proc$time_elapsed_ms) / 1000)
source("~/proj/navon/analysis/lib/load_process/load_process.R")
source("~/proj/navon/analysis/lib/load_process/load_process.R")
# Chunk 1: setup
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE,
fig.align = "center", fig.width = 9,
fig.height = 6, results = "asis")
options(knitr.kable.NA = "")
cli.progress_show_after <- 0
# Suppress summarise info
options(dplyr.summarise.inform = FALSE)
# Chunk 2: lib
library(here)
library(readr)
library(dplyr)
library(tidyr)
library(stringr)
library(cli) # For printing error messages
library(glue) # To make writing error message strings easier
source(here::here("lib", "load_process", "load_process.R"))
# Chunk 3: config
reprocess_task_data <- TRUE
reprocess_ehi_data <- TRUE
reprocess_demographics_data <- TRUE
reprocess_end_data <- TRUE
resummarize_task_data <- TRUE
resummarize_ehi_data <- TRUE
resummarize_demographics_data <- TRUE
resummarize_end_data <- TRUE
# reprocess_task_data <- FALSE
# reprocess_ehi_data <- FALSE
# reprocess_demographics_data <-FALSE
# reprocess_end_data <- FALSE
#
# resummarize_task_data <- FALSE
# resummarize_ehi_data <- FALSE
# resummarize_demographics_data <- FALSE
# resummarize_end_data <- FALSE
# Chunk 4: load_process_task
data_dir <- here::here("data")
input_dir <- here::here(data_dir, "input_prepilot")
proc_dir <- here::here(data_dir, "proc_prepilot")
## If data have been processed already, set to FALSE
if (reprocess_task_data == TRUE) {
load_and_process(input_dir, proc_dir, data_type = "task")
}
# Chunk 5: load_process_surveys
if (reprocess_ehi_data == TRUE) {
load_and_process(input_dir, proc_dir, data_type = "ehi")
}
#TODO: Process demographic, end question data
if (reprocess_demographics_data == TRUE) {
load_and_process(input_dir, proc_dir, data_type = "demographics")
}
if (reprocess_end_data == TRUE) {
load_and_process(input_dir, proc_dir, data_type = "end")
}
# Chunk 6: debug_survey
## For testing: step through load_and_process for an individual input file
#  data_type <- "task"
#  input_files <- get_input_paths(input_dir, data_type)
#
# input_dir
#
# input_files
# n_input_files <- length(input_files)
# n_input_files
# input_path <- input_files[1] ## This will be in s a loop
# input_path
# data_raw <- load_raw(input_path, data_type)
# data_raw
# subject_id <- data_raw$subject %>% first() %>% as.character()
# subject_id
# data_raw
# data_recoded <- recode_raw(data_raw, data_type)
# data_recoded
# data_cleaned <- clean_recoded(data_recoded, data_type)
# data_cleaned
# data_tests(data_cleaned, data_type)
# save_cleaned(data_cleaned, proc_dir, data_type)
# Chunk 7: calculate_variables
## Load processed data
ind_input_dir <- here(proc_dir, "individual")
summary_output_dir <- here(proc_dir, "summary")
## Create summary row for each subject
## TODO: Add overall median RT to summary spreadsheet
if (resummarize_task_data == TRUE) {
## Create summarized task data (saves to tsv as a side effect)
task_summary <-
load_and_summarize_proc(ind_input_dir, summary_output_dir,
data_type = "task")
}
if (resummarize_ehi_data == TRUE) {
## Create summarized task data (saves to tsv as a side effect)
ehi_summary <-
load_and_summarize_proc(ind_input_dir, summary_output_dir,
data_type = "ehi")
}
## TODO: (URGENT) fix logic for race variable -- always shows "multiple"
if (resummarize_demographics_data == TRUE) {
## Create summarized demographics data (saves to tsv as a side effect)
demo_summary <-
load_and_summarize_proc(ind_input_dir, summary_output_dir,
data_type = "demographics")
}
if (resummarize_end_data == TRUE) {
## Create summarized end question data (saves to tsv as a side effect)
end_summary <-
load_and_summarize_proc(ind_input_dir, summary_output_dir,
data_type = "end")
}
# Chunk 8: debug_summary
# group_summary <- tibble(
#   subject = as.character(),
#   ehi_i1_writing = as.numeric(),
#   ehi_i2_throwing = as.numeric(),
#   ehi_i3_toothbrush = as.numeric(),
#   ehi_i4_spoon = as.numeric(),
#   ehi_total = as.numeric()
# )
#
#
# group_summary <- tibble(
#   subject = as.character(),
#   age = as.numeric(),
#   country = as.character(),
#   sex = as.character(),
#   education = as.character(),
#   race = as.character(),
#   hispanic_ethnicity = as.character()
# )
#
# group_summary <- tibble(
#   subject = as.character(),
#   task_experience_response = as.character(),
#   task_experience_other_response = as.character(),
#   open_ended_feedback_response = as.character()
# )
#
# group_summary <- tibble(
#   subject = as.character(),
#   first_block = as.character(),
#   acc_slash = as.numeric(),
#   acc_z = as.numeric(),
#   acc_absent = as.numeric(),
#   acc_present = as.numeric(),
#   acc_global_LVF = as.numeric(),
#   acc_global_RVF = as.numeric(),
#   acc_local_LVF = as.numeric(),
#   acc_local_RVF = as.numeric(),
#   rt_global_LVF = as.numeric(),
#   rt_global_RVF = as.numeric(),
#   rt_local_LVF = as.numeric(),
#   rt_local_RVF = as.numeric(),
#   exclude_many_gos = as.logical(),
#   exclude_low_acc = as.logical(),
#   exclude_low_rt = as.logical(),
#   exclude_high_rt = as.logical(),
#   exclude = as.logical()
# )
#
# data_type = "task"
# input_files <- get_input_paths(ind_input_dir, data_type = data_type,
#                                pattern = "*.tsv")
#
# input_path <- input_files[1]
# input_path
# ind_proc <- load_proc(input_path, data_type = data_type)
#
# duration_s <- last(ind_proc$time_elapsed_ms) / 1000
# duration_s
#
#
# ind_summary <- summarize_ind(ind_proc, data_type = data_type)
# ind_summary
#
#
# group_summary <- group_summary %>% add_row(ind_summary)
# group_summary
# Chunk 9: combine
## Combine summaries into one big table, with a wide row for each subject.
summary <- task_summary %>%
left_join(ehi_summary) %>%
left_join(demo_summary) %>%
left_join(end_summary)
write_tsv(summary, here::here(summary_output_dir, "summary.tsv"))
# Chunk 10: analyze_rt
## Reaction time analyses
# Chunk 11: report_rt
## Visualize per-trial RT data (make absent one color, present another)
## Report RT data by condition
# Chunk 12: report_acc
## Report accuracy data by condition
# Chunk 13: report_duration
## Report experiment duration
# Chunk 14: report_demographics
## Summarize demographic data
## And "end question" responses
# Chunk 15
## Create individual summary data
## Add to a summary spreadsheet
# Chunk 1: setup
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE,
fig.align = "center", fig.width = 9,
fig.height = 6, results = "asis")
options(knitr.kable.NA = "")
cli.progress_show_after <- 0
# Suppress summarise info
options(dplyr.summarise.inform = FALSE)
# Chunk 2: lib
library(here)
library(readr)
library(dplyr)
library(tidyr)
library(stringr)
library(cli) # For printing error messages
library(glue) # To make writing error message strings easier
source(here::here("lib", "load_process", "load_process.R"))
# Chunk 3: config
reprocess_task_data <- TRUE
reprocess_ehi_data <- TRUE
reprocess_demographics_data <- TRUE
reprocess_end_data <- TRUE
resummarize_task_data <- TRUE
resummarize_ehi_data <- TRUE
resummarize_demographics_data <- TRUE
resummarize_end_data <- TRUE
# reprocess_task_data <- FALSE
# reprocess_ehi_data <- FALSE
# reprocess_demographics_data <-FALSE
# reprocess_end_data <- FALSE
#
# resummarize_task_data <- FALSE
# resummarize_ehi_data <- FALSE
# resummarize_demographics_data <- FALSE
# resummarize_end_data <- FALSE
# Chunk 4: load_process_task
data_dir <- here::here("data")
input_dir <- here::here(data_dir, "input_0pt5")
proc_dir <- here::here(data_dir, "proc_0pt5")
## If data have been processed already, set to FALSE
if (reprocess_task_data == TRUE) {
load_and_process(input_dir, proc_dir, data_type = "task")
}
# Chunk 5: load_process_surveys
if (reprocess_ehi_data == TRUE) {
load_and_process(input_dir, proc_dir, data_type = "ehi")
}
#TODO: Process demographic, end question data
if (reprocess_demographics_data == TRUE) {
load_and_process(input_dir, proc_dir, data_type = "demographics")
}
if (reprocess_end_data == TRUE) {
load_and_process(input_dir, proc_dir, data_type = "end")
}
# Chunk 6: debug_survey
## For testing: step through load_and_process for an individual input file
#  data_type <- "task"
#  input_files <- get_input_paths(input_dir, data_type)
#
# input_dir
#
# input_files
# n_input_files <- length(input_files)
# n_input_files
# input_path <- input_files[1] ## This will be in s a loop
# input_path
# data_raw <- load_raw(input_path, data_type)
# data_raw
# subject_id <- data_raw$subject %>% first() %>% as.character()
# subject_id
# data_raw
# data_recoded <- recode_raw(data_raw, data_type)
# data_recoded
# data_cleaned <- clean_recoded(data_recoded, data_type)
# data_cleaned
# data_tests(data_cleaned, data_type)
# save_cleaned(data_cleaned, proc_dir, data_type)
# Chunk 7: calculate_variables
## Load processed data
ind_input_dir <- here(proc_dir, "individual")
summary_output_dir <- here(proc_dir, "summary")
## Create summary row for each subject
## TODO: Add overall median RT to summary spreadsheet
if (resummarize_task_data == TRUE) {
## Create summarized task data (saves to tsv as a side effect)
task_summary <-
load_and_summarize_proc(ind_input_dir, summary_output_dir,
data_type = "task")
}
if (resummarize_ehi_data == TRUE) {
## Create summarized task data (saves to tsv as a side effect)
ehi_summary <-
load_and_summarize_proc(ind_input_dir, summary_output_dir,
data_type = "ehi")
}
## TODO: (URGENT) fix logic for race variable -- always shows "multiple"
if (resummarize_demographics_data == TRUE) {
## Create summarized demographics data (saves to tsv as a side effect)
demo_summary <-
load_and_summarize_proc(ind_input_dir, summary_output_dir,
data_type = "demographics")
}
if (resummarize_end_data == TRUE) {
## Create summarized end question data (saves to tsv as a side effect)
end_summary <-
load_and_summarize_proc(ind_input_dir, summary_output_dir,
data_type = "end")
}
# Chunk 8: debug_summary
# group_summary <- tibble(
#   subject = as.character(),
#   ehi_i1_writing = as.numeric(),
#   ehi_i2_throwing = as.numeric(),
#   ehi_i3_toothbrush = as.numeric(),
#   ehi_i4_spoon = as.numeric(),
#   ehi_total = as.numeric()
# )
#
#
# group_summary <- tibble(
#   subject = as.character(),
#   age = as.numeric(),
#   country = as.character(),
#   sex = as.character(),
#   education = as.character(),
#   race = as.character(),
#   hispanic_ethnicity = as.character()
# )
#
# group_summary <- tibble(
#   subject = as.character(),
#   task_experience_response = as.character(),
#   task_experience_other_response = as.character(),
#   open_ended_feedback_response = as.character()
# )
#
# group_summary <- tibble(
#   subject = as.character(),
#   first_block = as.character(),
#   acc_slash = as.numeric(),
#   acc_z = as.numeric(),
#   acc_absent = as.numeric(),
#   acc_present = as.numeric(),
#   acc_global_LVF = as.numeric(),
#   acc_global_RVF = as.numeric(),
#   acc_local_LVF = as.numeric(),
#   acc_local_RVF = as.numeric(),
#   rt_global_LVF = as.numeric(),
#   rt_global_RVF = as.numeric(),
#   rt_local_LVF = as.numeric(),
#   rt_local_RVF = as.numeric(),
#   exclude_many_gos = as.logical(),
#   exclude_low_acc = as.logical(),
#   exclude_low_rt = as.logical(),
#   exclude_high_rt = as.logical(),
#   exclude = as.logical()
# )
#
# data_type = "task"
# input_files <- get_input_paths(ind_input_dir, data_type = data_type,
#                                pattern = "*.tsv")
#
# input_path <- input_files[1]
# input_path
# ind_proc <- load_proc(input_path, data_type = data_type)
#
# duration_s <- last(ind_proc$time_elapsed_ms) / 1000
# duration_s
#
#
# ind_summary <- summarize_ind(ind_proc, data_type = data_type)
# ind_summary
#
#
# group_summary <- group_summary %>% add_row(ind_summary)
# group_summary
# Chunk 9: combine
## Combine summaries into one big table, with a wide row for each subject.
summary <- task_summary %>%
left_join(ehi_summary) %>%
left_join(demo_summary) %>%
left_join(end_summary)
write_tsv(summary, here::here(summary_output_dir, "summary.tsv"))
# Chunk 10: analyze_rt
## Reaction time analyses
# Chunk 11: report_rt
## Visualize per-trial RT data (make absent one color, present another)
## Report RT data by condition
# Chunk 12: report_acc
## Report accuracy data by condition
# Chunk 13: report_duration
## Report experiment duration
# Chunk 14: report_demographics
## Summarize demographic data
## And "end question" responses
# Chunk 15
## Create individual summary data
## Add to a summary spreadsheet
