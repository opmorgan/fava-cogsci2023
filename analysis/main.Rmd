---
title: "Bilateral navon task analysis"
author: "Owen Morgan"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    highlight: zenburn
    editor_options:
      chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE,
                      fig.align = "center", fig.width = 9,
                      fig.height = 6, results = "asis")
options(knitr.kable.NA = "")

cli.progress_show_after <- 0
```

```{r lib}
library(here)
# library(tidyverse)
library(readr)
library(dplyr)
library(stringr)
library(cli) # For printing error messages
library(glue) # To make writing error message strings easier

source(here::here("lib", "load_process_task.R"))
```

## Load and check quality of individual-level data
### Task data
```{r load_process_task}
data_dir <- here::here("data")
input_dir <- here::here(data_dir, "input_0pt5")
proc_dir <- here::here(data_dir, "proc_0pt5")

## If data have been processed already, set to FALSE
reprocess_individual_data <- FALSE
if (reprocess_individual_data == TRUE) {
  load_and_process(input_dir, proc_dir, data_type = "task")
}
```

```{r test_load, include = F}
## For testing: step through load_and_process for an individual input file
data_type <- "task"
input_files <- get_input_paths(input_dir, data_type)
input_files
n_input_files <- length(input_files)
n_input_files
input_path <- input_files[3] ## todo: make this a loop
input_path
data_raw <- load_raw(input_path, data_type)
data_raw
subject_id <- data_raw$subject %>% first() %>% as.character()
data_tests(data_raw, data_type)
data_recoded <- recode_raw(data_raw, data_type)
data_recoded
data_cleaned <- clean_recoded(data_recoded, data_type)
data_cleaned
save_cleaned(data_cleaned, proc_dir, data_type)
```

## Load and process demographics & Survey data
```{r, load_survey}
# Load TSV input files with extension .iqdat
data_dir <- here::here("data")
input_dir <- here::here(data_dir, "input_0pt4")
proc_dir <- here::here(data_dir, "proc_0pt4")

## Load demographic_data
data_subdir <- here(input_dir, "survey", "demographics")
input_files <- list.files(path = data_subdir, pattern = "*.iqdat",
                          full.names = TRUE)
data_demo <- read_tsv(input_files[1])

## Load EHI data
data_subdir <- here(input_dir, "survey", "ehi_short")
input_files <- list.files(path = data_subdir, pattern = "*.iqdat",
                          full.names = TRUE)
data_ehi <- read_tsv(input_files[1])

## Load end question data
data_subdir <- here(input_dir, "survey", "end_questions")
input_files <- list.files(path = data_subdir, pattern = "*.iqdat",
                          full.names = TRUE)
data_end <- read_tsv(input_files[1])
```

## Find calculated variables, save summary data
```{r}
## Load processed data
```

```{r calculate_percent_correct}
## Calculate percent correct for each block, separating present and absent trials
response_counts_block_pa <- data_proc %>% 
  group_by(block, block_type, target_present) %>% 
  summarize(total_responses = n(),
            n_present_resp = sum(response_log),
            n_absent_resp = total_responses - n_present_resp,
            n_correct = sum(correct),
            percent_correct = 100*(n_correct / total_responses)) 
## Inspect accuracy by block, present/absent
response_counts_block_pa

## Calculate percent correct for each block, collapsing present and absent trials
response_counts_by_block <- data_proc %>% 
  group_by(block, block_type) %>% 
  summarize(total_responses = n(),
            n_present_resp = sum(response_log),
            n_absent_resp = total_responses - n_present_resp,
            n_correct = sum(correct),
            percent_correct = 100*(n_correct / total_responses)) 
## Inspect accuracy by block, present/absent
response_counts_by_block
```

## Analyze data and report results
```{r exclusions}
## TODO: Exclusions

## Responded "go" almost every time?
exclude_all_gos = 0

response_counts_block_main <- response_counts_by_block %>% 
  filter(phase == "main")

for (block in response_counts_block_main$block) {
  print(block)
  print(str_c("Number of 'go' responses: ", ))
}

go_counts <- response_counts_by_block %>% 
  filter(phase == "main") %>% 
  .[["n_present_resp"]]

go_counts

## Accuracy below 60% on any main block?
exclude_low_acc = 0

#### Accuracy analyses

## Check for 60% or lower accuracy on either trial block
```

```{r inspect_proc}
## Inspect data
data_proc %>% colnames()
data_proc %>% head()

## Check that blocks have the right trials
data_proc %>% group_by(block) %>% count()

## Check that response counts look about right
data_proc %>% group_by(response) %>% count()

## Inspect responses
data_proc %>% group_by(response) %>% count()
data_proc %>% group_by(response, correct) %>% count()

## TODO: inspect duration, total and by block

## TODO: inspect demographics, EHI, duration
```

```{r analyze_rt}
## Reaction time analyses
```

```{r report_rt}
## Visualize per-trial RT data (make absent one color, present another)

## Report RT data by condition
```

```{r report_acc}
## Report accuracy data by condition
```

```{r report_duration}
## Report experiment duration
```

```{r report_demographics}
## Summarize demographic data
## And "end question" responses
```

```{r}
## Create individual summary data
## Add to a summary spreadsheet
```



