---
title: "Bilateral navon task analysis"
author: "Owen Morgan"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    highlight: zenburn
    editor_options:
      chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE,
                      fig.align = "center", fig.width = 9,
                      fig.height = 6, results = "asis")
options(knitr.kable.NA = "")

cli.progress_show_after <- 0
```

```{r lib}
library(here)
# library(tidyverse)
library(readr)
library(dplyr)
library(tidyr)
library(stringr)
library(cli) # For printing error messages
library(glue) # To make writing error message strings easier

source(here::here("lib", "load_process", "load_process.R"))
```

## Load and check quality of individual-level data
### Task data
```{r load_process_task}
data_dir <- here::here("data")
input_dir <- here::here(data_dir, "input_0pt5")
proc_dir <- here::here(data_dir, "proc_0pt5")

## If data have been processed already, set to FALSE
reprocess_task_data <- FALSE
if (reprocess_task_data == TRUE) {
  load_and_process(input_dir, proc_dir, data_type = "task")
}
```

```{r temp_dev}
# data_type <- "task"
# input_files <- get_input_paths(input_dir, data_type)
# input_files
# n_input_files <- length(input_files)
# n_input_files
# input_path <- input_files[5] ## this will be in a loop
# input_path
# data_raw <- load_raw(input_path, data_type)
# data_raw
# subject_id <- data_raw$subject %>% first() %>% as.character()
# subject_id
# 
# data_recoded <- recode_raw(data_raw, data_type)
# data_recoded
# 
# data_recoded %>%
#   select(stimulus_left, stimulus_right, target, level, field)
# 
# data_cleaned <- clean_recoded(data_recoded, data_type)
# data_cleaned
# data_cleaned %>% select(block_type, block_response, blocknum, target, level, field)
# 
# data_cleaned %>% data_tests(data_type)
```


## Load and process survey data
```{r load_process_surveys}
reprocess_ehi_data <- FALSE
if (reprocess_ehi_data == TRUE) {
  load_and_process(input_dir, proc_dir, data_type = "ehi")
}

#TODO: Process demographic, end question data
reprocess_demographics_data <- FALSE
if (reprocess_demographics_data == TRUE) {
  load_and_process(input_dir, proc_dir, data_type = "demographics")
}

reprocess_end_data <-FALSE
if (reprocess_end_data == TRUE) {
  load_and_process(input_dir, proc_dir, data_type = "end")
}
```

```{r temp_load_process, include = F}
# ## For testing: step through load_and_process for an individual input file
# data_type <- "demographics"
# input_files <- get_input_paths(input_dir, data_type)
# input_files
# n_input_files <- length(input_files)
# n_input_files
# input_path <- input_files[1] ## todo: make this a loop
# input_path
# data_raw <- load_raw(input_path, data_type)
# data_raw
# subject_id <- data_raw$subject %>% first() %>% as.character()
# subject_id
# data_recoded <- recode_raw(data_raw, data_type)
# data_recoded
# data_cleaned <- clean_recoded(data_recoded, data_type)
# data_cleaned
# data_cleaned$ehi_total
# data_tests(data_cleaned, data_type)
# save_cleaned(data_cleaned, proc_dir, data_type)
```

## Find calculated variables, save summary data
```{r calculate_variables}
## Load processed data
ind_input_dir <- here(proc_dir, "individual")
summary_output_dir <- here(proc_dir, "summary")

## Create summary row for each subject

load_and_summarize_proc(ind_input_dir, summary_output_dir, data_type = "task")
```

```{r exclusions}
## TODO: exclusions (These should be calculated and added to each subject's summary data)

## responded "go" almost every time?
exclude_all_gos = 0

response_counts_block_main <- response_counts_by_block %>%
filter(phase == "main")

for (block in response_counts_block_main$block) {
print(block)
print(str_c("number of 'go' responses: ",))
}

go_counts <- response_counts_by_block %>%
filter(phase == "main") %>%
.[["n_present_resp"]]

go_counts

## accuracy at 80% or lower on any main block?
exclude_low_acc = 0

#### accuracy analyses
```

## Analyze data and report results


```{r inspect_proc}
## Inspect data
data_proc %>% colnames()
data_proc %>% head()

## Check that blocks have the right trials
data_proc %>% group_by(block) %>% count()

## Check that response counts look about right
data_proc %>% group_by(response) %>% count()

## Inspect responses
data_proc %>% group_by(response) %>% count()
data_proc %>% group_by(response, correct) %>% count()

## TODO: inspect duration, total and by block

## TODO: inspect demographics, EHI, duration
```

```{r analyze_rt}
## Reaction time analyses
```

```{r report_rt}
## Visualize per-trial RT data (make absent one color, present another)

## Report RT data by condition
```

```{r report_acc}
## Report accuracy data by condition
```

```{r report_duration}
## Report experiment duration
```

```{r report_demographics}
## Summarize demographic data
## And "end question" responses
```

```{r}
## Create individual summary data
## Add to a summary spreadsheet
```



