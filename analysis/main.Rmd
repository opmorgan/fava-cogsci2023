---
title: "Bilateral navon task analysis"
author: "Owen Morgan"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    highlight: zenburn
    editor_options:
      chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE,
                      fig.align = "center", fig.width = 9,
                      fig.height = 6, results = "asis")
options(knitr.kable.NA = "")

cli.progress_show_after <- 0
```

```{r lib}
library(here)
# library(tidyverse)
library(readr)
library(dplyr)
library(tidyr)
library(stringr)
library(testthat) # For writing tests
library(cli) # For printing error messages
library(glue) # To make writing error message strings easier

source(here::here("lib", "load_process", "load_process.R"))
```

## Load and check quality of individual-level data
### Task data
```{r load_process_task}
data_dir <- here::here("data")
input_dir <- here::here(data_dir, "input_0pt5")
proc_dir <- here::here(data_dir, "proc_0pt5")

## If data have been processed already, set to FALSE
reprocess_task_data <- FALSE
if (reprocess_task_data == TRUE) {
  load_and_process(input_dir, proc_dir, data_type = "task")
}
```

```{r temp_dev}
data_type <- "task"
input_files <- get_input_paths(input_dir, data_type)
input_files
n_input_files <- length(input_files)
n_input_files
input_path <- input_files[1] ## this will be in a loop
input_path
data_raw <- load_raw(input_path, data_type)
data_raw
subject_id <- data_raw$subject %>% first() %>% as.character()
subject_id
data_tests(data_raw, data_type)

data_recoded <- recode_raw(data_raw, data_type)
data_recoded

data_recoded %>% 
  select(stimulus_left, stimulus_right, target, level, field)

data_cleaned <- clean_recoded(data_recoded, data_type)
data_cleaned
data_cleaned %>% select(block_type, block_response, block, blocknum, target, level, field)


## TEST that:
## (1) There are 160 trials  where block_type = "main"
main_trials <- data_cleaned %>% filter(block_type == "main")
n_main_trials <- main_trials %>%  dim() %>% .[[1]]
if (n_main_trials != 160) {
  cli::cli_abort(c(
    "{.var n_main_trials} is equal to {n_main_trials}",
    "x" = str_c("The number of main trials is not equal to 160")
  ))
}
## (1) Of these 160 trials, 80 have block = "main_z"; 80, "main_slash"
for (block_response_var in c("z", "slash")) {
  print(block_response_var)
  block_response_var <- "z"
  main_block_trials <- main_trials %>% filter(block_response == "z")
  n_main_block_trials <- main_block_trials %>% dim() %>% .[[1]]
  if (n_main_block_trials != 80) {
  cli::cli_abort(c(
    "{.var n_main_block_trials} is equal to {n_main_block_trials}",
    "x" = str_c("The number of main block trials ({block_response_var}) is not equal to 160")
  ))
}
  n_main_block_trials
}

## (1) In each block of 80 trials, 80% (64/80) of trials are target-present (they contain a circle or a square), and 20% (16/80) of trials are target-absent
## (1) In each block of 80 trials, 32 have global targets; 32, local.
## (1) Of the 32 global targets, 16 are LVF and 16 RVF; of the 32 local, 16 are LVF/RVF.
## (1) When "target" is anything other than absent, the column "target_present" has a "1"; if not, a "0"
```


## Load and process survey data
```{r load_process_surveys}
reprocess_ehi_data <- TRUE
if (reprocess_ehi_data == TRUE) {
  load_and_process(input_dir, proc_dir, data_type = "ehi")
}

#TODO: Process demographic, end question data
reprocess_demographics_data <- FALSE
if (reprocess_ehi_data == TRUE) {
  load_and_process(input_dir, proc_dir, data_type = "demographics")
}

reprocess_end_data <-FALSE
if (reprocess_end_data == TRUE) {
  load_and_process(input_dir, proc_dir, data_type = "end")
}
```

```{r temp_load_process, include = F}
## For testing: step through load_and_process for an individual input file
data_type <- "demographics"
input_files <- get_input_paths(input_dir, data_type)
input_files
n_input_files <- length(input_files)
n_input_files
input_path <- input_files[1] ## todo: make this a loop
input_path
data_raw <- load_raw(input_path, data_type)
data_raw
subject_id <- data_raw$subject %>% first() %>% as.character()
subject_id
data_tests(data_raw, data_type)
data_recoded <- recode_raw(data_raw, data_type)
data_recoded
data_cleaned <- clean_recoded(data_recoded, data_type)
data_cleaned
data_cleaned$ehi_total
save_cleaned(data_cleaned, proc_dir, data_type)
```

## Find calculated variables, save summary data
```{r calculate_variables}
## Load processed data
ind_input_dir <- here(proc_dir, "individual")
summary_output_dir <- here(proc_dir, "summary")

## Create summary row for each subject
## TODO: add a column "first_block" (z, slash)
summarize_proc(ind_input_dir, summary_output_dir, data_type = "task")
```

```{r exclusions}
## TODO: exclusions (These should be calculated and added to each subject's summary data)

## responded "go" almost every time?
exclude_all_gos = 0

response_counts_block_main <- response_counts_by_block %>%
filter(phase == "main")

for (block in response_counts_block_main$block) {
print(block)
print(str_c("number of 'go' responses: ",))
}

go_counts <- response_counts_by_block %>%
filter(phase == "main") %>%
.[["n_present_resp"]]

go_counts

## accuracy at 80% or lower on any main block?
exclude_low_acc = 0

#### accuracy analyses
```

## Analyze data and report results


```{r inspect_proc}
## Inspect data
data_proc %>% colnames()
data_proc %>% head()

## Check that blocks have the right trials
data_proc %>% group_by(block) %>% count()

## Check that response counts look about right
data_proc %>% group_by(response) %>% count()

## Inspect responses
data_proc %>% group_by(response) %>% count()
data_proc %>% group_by(response, correct) %>% count()

## TODO: inspect duration, total and by block

## TODO: inspect demographics, EHI, duration
```

```{r analyze_rt}
## Reaction time analyses
```

```{r report_rt}
## Visualize per-trial RT data (make absent one color, present another)

## Report RT data by condition
```

```{r report_acc}
## Report accuracy data by condition
```

```{r report_duration}
## Report experiment duration
```

```{r report_demographics}
## Summarize demographic data
## And "end question" responses
```

```{r}
## Create individual summary data
## Add to a summary spreadsheet
```



