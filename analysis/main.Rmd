---
title: "Bilateral navon task analysis"
author: "Owen Morgan"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    highlight: zenburn
    editor_options:
      chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE,
                      fig.align = "center", fig.width = 9,
                      fig.height = 6, results = "asis")
options(knitr.kable.NA = "")

cli.progress_show_after <- 0

# Suppress summarise info
options(dplyr.summarise.inform = FALSE)
```

```{r lib}
library(here)
library(readr)
library(dplyr)
library(tidyr)
library(stringr)
library(cli) # For printing error messages
library(glue) # To make writing error message strings easier

source(here::here("lib", "load_process", "load_process.R"))
```

## Load and check quality of individual-level data
### Task data
```{r load_process_task}
data_dir <- here::here("data")
input_dir <- here::here(data_dir, "input_0pt5")
proc_dir <- here::here(data_dir, "proc_0pt5")

## If data have been processed already, set to FALSE
reprocess_task_data <- FALSE
if (reprocess_task_data == TRUE) {
  load_and_process(input_dir, proc_dir, data_type = "task")
}
```

## Load and process survey data
```{r load_process_surveys}
reprocess_ehi_data <- FALSE
if (reprocess_ehi_data == TRUE) {
  load_and_process(input_dir, proc_dir, data_type = "ehi")
}

#TODO: Process demographic, end question data
reprocess_demographics_data <- TRUE
if (reprocess_demographics_data == TRUE) {
  load_and_process(input_dir, proc_dir, data_type = "demographics")
}

reprocess_end_data <- TRUE
if (reprocess_end_data == TRUE) {
  load_and_process(input_dir, proc_dir, data_type = "end")
}
```

```{r debug_survey, include = F}
# ## For testing: step through load_and_process for an individual input file
data_type <- "end"
input_files <- get_input_paths(input_dir, data_type)
input_files
n_input_files <- length(input_files)
n_input_files
input_path <- input_files[2] ## This will be in s a loop
input_path
data_raw <- load_raw(input_path, data_type)
data_raw
subject_id <- data_raw$subject %>% first() %>% as.character()
subject_id
data_raw  
data_recoded <- recode_raw(data_raw, data_type)
data_recoded
data_cleaned <- clean_recoded(data_recoded, data_type)
data_cleaned
data_tests(data_cleaned, data_type)
save_cleaned(data_cleaned, proc_dir, data_type)
```

## Find calculated variables, save summary data
```{r calculate_variables}
## Load processed data
ind_input_dir <- here(proc_dir, "individual")
summary_output_dir <- here(proc_dir, "summary")

## Create summary row for each subject
## TODO: join survey data
## TODO (URGENT) fix exclusions code (currently, not excluding anyone)
## TODO: Add overall median RT to summary spreadsheet
load_and_summarize_proc(ind_input_dir, summary_output_dir, data_type = "task")
```

```{r debug_summary}
# input_files <- get_input_paths(ind_input_dir, data_type = "task",
#                                pattern = "*.tsv")
# 
# input_path <- input_files[2]
# input_path
# data_proc <- load_proc(input_path, data_type = "task")
# data_proc
# proc_summary <- summarize_ind(data_proc)
# proc_summary
# proc_summary %>% colnames
```

## Analyze data and report results, for each individual
```{r analyze_rt}
## Reaction time analyses
```

```{r report_rt}
## Visualize per-trial RT data (make absent one color, present another)

## Report RT data by condition
```

```{r report_acc}
## Report accuracy data by condition
```

```{r report_duration}
## Report experiment duration
```

```{r report_demographics}
## Summarize demographic data
## And "end question" responses
```

```{r}
## Create individual summary data
## Add to a summary spreadsheet
```

## Analyze group data and report results

