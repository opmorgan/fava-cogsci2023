---
title: "Action Asymmetry Pilot: Analyses"
author: "Owen Morgan"
date: "2022-11-08"
output: html_document
---

<style type="text/css">
  body{
  font-family: Avenir;
  font-size: 12pt;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE,
                      fig.align = "center", fig.width = 9,
                      fig.height = 6, results = "asis")
options(knitr.kable.NA = "")

cli.progress_show_after <- 0

## Do not use scientific notation until 9 decimal places.
options(scipen = 9, digits = 9)

# Suppress summarise info
options(dplyr.summarise.inform = FALSE)
```

```{r lib}
library(here)
library(tidyverse)
library(cli) # For printing error messages

library(lme4)
library(emmeans)
library(broom)
library(gt)

source(here::here("lib", "load_process", "load_process.R"))
source(here::here("lib", "util.R"))
```

```{r config}
data_dir <- here::here("data")
proc_dir <- here::here(data_dir, "proc_pilot")

use_cached_model_rt <- TRUE
use_cached_model_acc <- TRUE
```

## {.tabset}
```{r load_data}
## Load long data table, and filter out excluded subjects
aah <- readr::read_tsv(
  here(proc_dir, "aah_long.tsv"),
  col_types = cols(
    subject = col_character(),
    block_response = col_character(),
    target = col_character(),
    level = col_character(),
    field = col_character(),
    correct = col_logical(),
    rt = col_double(),
    first_block = col_character(),
    ehi_total = col_double(),
    age = col_double(),
    country = col_character(),
    sex = col_character(),
    education = col_double(),
    race = col_character(),
    hispanic_ethnicity = col_character(),
    rt_overall = col_double(),
    duration_s = col_double(),
    task_experience_response = col_character(),
    task_experience_other_response = col_logical(),
    open_ended_feedback_response = col_character(),
    exclude_many_gos = col_logical(),
    exclude_low_acc = col_logical(),
    exclude_low_rt = col_logical(),
    exclude_high_rt = col_logical(),
    exclude_country = col_logical(),
    exclude_age = col_logical(),
    exclude_done_before = col_logical(),
    exclude_no_ehi = col_logical(),
    exclude = col_logical()
  )
) |>
  filter(exclude == 0)
```

### Pilot analyses: Field x Level interaction {.tabset .tabset-pills .active}

In our pilot sample of right handers, do we see the typical field x level interaction? That is, do participants show a relative bias for global shapes in the left visual field (LVF)?
<br>

#### Reaction time
Reaction time is modeled as a linear effect of field and level, using data from every trial:
<br>
<br>
`lmer( rt ~ field + level + field:level + (1 | subject) )`
<br>
<br>
*Discussion question*: Should any variables not-of-interest be included as covariates? E.g., sex, target (circle/square), first block (z or slash), overall median rt (ms).
```{r rt_model}
## Make a linear model using data from every trial.
## Fixed effects: field, level (and their interaction)
## Random effects: subject.
## rt ~ field + level + field:level + (1 | subject)
rt_model <- lmer(rt ~ field:level + field + level + (1 | subject), data = aah)

if (use_cached_model_rt == FALSE) {
  ## Create emmeans model object, and manually cache it.
  rt_emm <- emmeans(rt_model, ~ field * level, pbkrtest = 13184)
  
  ## Manually cache model
  saveRDS(rt_emm, here("manual_cache", "rt_emm.rds"))
  
} else if (use_cached_model_rt == TRUE) {
  ## Load cached model
  rt_emm <- readRDS(here("manual_cache", "rt_emm.rds"))
}
```
<!-- Test for field x level interaction, using the anova() function: is the interaction model's fit significantly different from the no-interaction model's fit? -->
<br>
```{r rt_interaction_anova}
## Use anova() on competing models to test 2-way interaction.
interaction_stats <-
  function(model_with_interaction,
           model_with_no_interaction) {
    return(anova(model_with_interaction, model_with_no_interaction))
  }

rt_model_no_interaction <- update(rt_model, . ~ . - field:level)
interaction_anova <- interaction_stats(rt_model, rt_model_no_interaction)
interaction_anova |>
  as_tibble() |>
  rename(p.value = `Pr(>Chisq)`) |> 
  format_p.value() |> 
  pretty_table() |> 
  tab_header(title = "Field by level interaction (RT)", 
             subtitle = "ANOVA: compare models with vs. without interaction term") 
```
<br>
```{r rt_interacion_aov}
## Use aov to test 2-way interaction with a traditional F-test.
rt_aov <- aov(rt ~ field + level + field:level, data = aah)
rt_aov_summary <- summary(rt_aov)
rt_aov_summary |> (\(.) .[[1]])() |> tidy() |>
  format_p.value() |> 
  pretty_table() |>
  tab_header(title = "Field by level interaction (RT)",
             subtitle = "Old-school F-test")
```
<br>
<!-- Test for field x level interaction, using emmeans() - is the model's interaction effect estimate significantly different from zero? -->
```{r rt_interaction_emm}
## Use emmeans() to test 2-way interaction.
rt_interaction_emm <- rt_emm |>
  contrast(interaction = c("consec")) |>
  summary(infer = T)
#rt_interaction_emm

rt_interaction_emm |>
  as_tibble() |>
  format_p.value() |> 
  pretty_table() |>
  tab_header(title = "Field by level interaction (RT)",
             subtitle = "Compare effect estimate to zero with emmeans()") |>
  tab_footnote(footnote = "A negative number means global bias is stronger in LVF",
               locations = cells_column_labels(columns = estimate)) |>
  tab_footnote(footnote = "Two-sided",
               locations = cells_column_labels(columns = p.value)) |>
  tab_footnote(footnote = "Confidence level: 95%",
               locations = cells_column_labels(columns = lower.CL)) |>
  tab_footnote(footnote = "Degrees-of-freedom method: kenward-roger",
               locations = cells_column_labels(columns = df))
```
<br>
```{r rt_field_bias}
rt_field_bias_emm <- rt_emm |>
  contrast("pairwise") |>
  summary(infer = T, adjust = "none", rows = c(3, 4))
#rt_field_bias_emm

rt_field_bias <- rt_field_bias_emm |>  
  as_tibble() |> 
  filter(contrast %in%
           c("LVF global - LVF local", "RVF global - RVF local"))

rt_field_bias |>
  format_p.value() |> 
  pretty_table() |>
  tab_header(title = "Global bias by field (RT)") |>
  tab_footnote(footnote = "A negative number means global bias (faster RT for global)",
               locations = cells_column_labels(columns = estimate)) |>
  tab_footnote(footnote = "Confidence level: 95%",
               locations = cells_column_labels(columns = lower.CL)) |>
  tab_footnote(footnote = "Two-sided, uncorrected",
               locations = cells_column_labels(columns = p.value)) |>
  tab_footnote(footnote = "Degrees-of-freedom method: kenward-roger",
               locations = cells_column_labels(columns = df))
```
<br>
```{r rt_by_field_level}
rt_modelled <- summary(rt_emm, type = "response")
rt_modelled |>
  as_tibble() |>
  arrange(field) |>
  pretty_table() |>
  tab_header(title = "RT estimates by field and level (from model)") |>
  tab_footnote(footnote = "Confidence level: 95%",
               locations = cells_column_labels(columns = lower.CL)) |>
  tab_footnote(footnote = "Degrees-of-freedom method: kenward-roger",
               locations = cells_column_labels(columns = df))
```
<br>
```{r rt_descriptive}
rt_descriptive <- aah |>
  group_by(field, level) |>
  summarize(
    median = median(rt),
    mean = mean(rt),
    SE = sd(rt) / sqrt(length((rt)))
  )

rt_descriptive |>
  pretty_table() |>
  tab_header(title = "RT estimates by field and level (descriptive)")
```
<br>

#### Accuracy
Accuracy is modeled as a binomial effect of field and level, using data from every trial (correct/incorrect):
<br>
<br>
`glmer( correct ~ field + level + field:level + (1 | subject), family = "binomial" )`
<br>
<br>
```{r acc_model}
## Make a binomial logistic model using data from every trial.
## Fixed effects: field, level (and their interaction)
## Random effects: subject.
## correct ~ field + level + field:level + (1 | subject)
acc_model <- glmer(correct ~ field:level + field + level + (1 | subject),
                   data = aah,
                   family = "binomial")

if (use_cached_model_acc == FALSE) {
  ## Create emmeans model object, and manually cache it.
  acc_emm <- emmeans(acc_model, ~ field * level)
  
  ## Manually cache model
  saveRDS(acc_emm, here("manual_cache", "acc_emm.rds"))
  
} else if (use_cached_model_acc == TRUE) {
  ## Load cached model
  acc_emm <- readRDS(here("manual_cache", "acc_emm.rds"))
}
```
<!-- Test for field x level interaction, using the anova() function: is the interaction model's fit significantly different from the no-interaction model's fit? -->
<br>
```{r acc_interaction_anova}
## Use anova() to test 2-way interaction effect.
interaction_stats <-
  function(model_with_interaction,
           model_with_no_interaction) {
    return(anova(model_with_interaction, model_with_no_interaction))
  }

acc_model_no_interaction <- update(acc_model, . ~ . - field:level)
interaction_anova <- interaction_stats(acc_model, acc_model_no_interaction)
#interaction_anova
interaction_anova |>
  as_tibble() |>
  pretty_table() |> 
  tab_header(title = "Field by level interaction (Accuracy)", 
             subtitle = "ANOVA: compare models with vs. without interaction term") 
```
<br>
<!-- Test for field x level interaction, using emmeans() - is the model's interaction effect estimate significantly different from zero? -->
```{r acc_interaction_emm}
## Is there an interaction of field x level?
## Use an emmeans contrast
acc_interaction_emm <- acc_emm |>
  contrast(interaction = c("consec")) |>
  summary(infer = T, type = "response")
#acc_interaction_emm

acc_interaction_emm |>
  as_tibble() |>
  format_p.value() |> 
  pretty_table() |>
  tab_header(title = "Field by level interaction (Accuracy)",
             subtitle = "Compare effect estimate to zero with emmeans()") |>
  tab_footnote(footnote = "Backtransformed to odds ratio from log odds ratio; tests are performed on log odds ratio scale.",
               locations = cells_column_labels(columns = odds.ratio)) |>
  tab_footnote(footnote = "I don't understand why df is 'Inf' here, but I think it is expected when emmeans does logistic regression. See emmeans FAQ: https://cran.r-project.org/web/packages/emmeans/vignettes/FAQs.html#asymp.",
               locations = cells_column_labels(columns = df)) |>
  tab_footnote(footnote = "Confidence level: 95%",
               locations = cells_column_labels(columns = asymp.LCL)) |>
  tab_footnote(footnote = "Two-sided",
               locations = cells_column_labels(columns = p.value))
```
<br>
```{r acc_field_bias}
acc_field_bias_emm <- acc_emm |>
  contrast("pairwise") |>
  summary(infer = T, adjust = "none", type = "response")
#acc_field_bias_emm

acc_field_bias <- acc_field_bias_emm |>
  as_tibble() |>
  filter(contrast %in%
           c("LVF global / LVF local", "RVF global / RVF local"))
#acc_field_bias

acc_field_bias |>
  format_p.value() |> 
  pretty_table() |>
  tab_header(title = "Global bias by field (Accuracy)") |>
  tab_footnote(footnote =  "Backtransformed to odds ratio from log odds ratio (tests are performed on log odds ratio scale). A ratio > 1 means global bias (more correct responses for global).",
               locations = cells_column_labels(columns = odds.ratio)) |>
  tab_footnote(footnote = "Confidence level: 95%",
               locations = cells_column_labels(columns = asymp.LCL)) |>
  tab_footnote(footnote = "Two-sided, uncorrected",
               locations = cells_column_labels(columns = p.value))
```
<br>
```{r acc_by_field_level}
acc_modelled <- summary(acc_emm, type = "response")
# acc_modelled
acc_modelled |>
  as_tibble() |> 
  arrange(field) |> 
  pretty_table() |>
  tab_header(title = "Accuracy estimates by field and level (from model)") |>
  tab_footnote(footnote = "Back-transformed to probability (% correct) from logit scale",
               locations = cells_column_labels(columns = prob)) |>
  tab_footnote(footnote = "Confidence level: 95%",
               locations = cells_column_labels(columns = asymp.LCL))
```
<br>
```{r acc_descriptive}
acc_descriptive <- response_counts_condition <- aah |>
      group_by(level, field, subject) |>
      summarize(
        total_responses = n(),
        n_present_resp = sum(correct),
        n_absent_resp = total_responses - n_present_resp,
        n_correct = sum(correct),
        percent_correct = 100 * (n_correct / total_responses)
      ) |> 
      group_by(field, level) |> 
      summarize(mean_subject_percent_correct = mean(percent_correct))
#acc_descriptive
    
acc_descriptive |>
  pretty_table() |>
  tab_header(title = "Accuracy estimates by field and level (descriptive)")
```
<br>

### Field x Level x Handedness
Once we collect data on lefties, we will test whether LVF-global bias is reduced or reversed with left handedness.
```{r analyze_main_rt}
## Reaction time analyses.
## Linear model using data from every trial.
## (1) Binary handedness. 
## rt ~ target*field*level*handedness

## (2) Continuous handedness

## As a sanity check, do parallel analyses with summary rt data instead of trial-level data.
```

```{r analyse_main_acc}
```

<!-- ## Visualize individual results -->
```{r visualize_individual_rt}
## Visualize per-trial RT data (make absent one color, present another)

```

<!-- ## Visualize group results -->
```{r}
## ## Visualize RT data by condition
```

```{r visualize_group_acc}
## Visualize accuracy data by condition
```
