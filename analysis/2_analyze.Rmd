---
title: "Bilateral Navon Task Analysis"
author: "Owen Morgan"
date: "2022-11-04"
output: html_document
---

<style type="text/css">
  body{
  font-family: Avenir;
  font-size: 12pt;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE,
                      fig.align = "center", fig.width = 9,
                      fig.height = 6, results = "asis")
options(knitr.kable.NA = "")

cli.progress_show_after <- 0

# Suppress summarise info
options(dplyr.summarise.inform = FALSE)
```

```{r lib}
library(here)
library(tidyverse)
library(cli) # For printing error messages

library(lme4)
library(emmeans)
library(broom)
library(kableExtra)
library(gt)

source(here::here("lib", "load_process", "load_process.R"))

#### Define functions for formatting and styling

## Function to make pretty table that rounds to 2 digits and stays in place
pretty_table <- function(table, title = NULL, digits = 3,
                         groupname_col = NULL
                         ) {
    gt(table, groupname_col = groupname_col) |> 
      tab_header(title = title) |> 
      fmt_missing(columns = everything(), missing_text = "-") |> 
      fmt_number(columns = where(is.numeric),
                 drop_trailing_zeros = T,
                 decimals = digits) |> 
   tab_style(
      #Apply new style to all column headers
     locations = cells_column_labels(columns = everything()),
     style     = list(
       #Give a thick border below
       # cell_borders(sides = "bottom", weight = px(2)),
       #Make text bold
       cell_text(weight = "bold")
     )
   )
}
```

```{r config}
data_dir <- here::here("data")
proc_dir <- here::here(data_dir, "proc_prepilot")
```


## Sample & Exclusions {.tabset}
```{r load_combined, include = F}
## Load combined trial-per-row data
aah_task_all <- readr::read_tsv(
  here(proc_dir, "combined", "combined_task.tsv"),
  col_types = cols(
    subject = col_character(),
    time_elapsed_ms = col_double(),
    blocknum = col_double(),
    block_type = col_character(),
    block_response = col_character(),
    trialnum = col_double(),
    target = col_character(),
    level = col_character(),
    field = col_character(),
    target_present = col_character(),
    response = col_character(),
    correct = col_double(),
    rt = col_double(),
  )
) |>
  filter(block_type == "main" & target_present == "yes") |>
  select(subject,
         block_response,
         target,
         level,
         field,
         correct,
         rt)

aah_summary_all <- load_summary() |>
  select(
    subject,
    first_block,
    ehi_total,
    age,
    country,
    sex,
    education,
    race,
    hispanic_ethnicity,
    rt_overall,
    duration_s,
    task_experience_response,
    task_experience_other_response,
    open_ended_feedback_response,
    exclude
  )

## Create long dataset with all subjects (included and excluded)
aah_all <- left_join(aah_task_all, aah_summary_all)
```

### Demographics (All)
```{r demographics_summary}
## Show one-row table with summary info
report_mean_sd <- function(numeric_vector) {
  return(str_c(
    round(mean(numeric_vector),2),
    " (", round(sd(numeric_vector), 2), ")"))
}

report_country <- function(country_char_vector) {
  n_us <- sum(country_char_vector == "US")
  n_not_us <- sum(country_char_vector != "US")
  return(str_c(n_us, "/", n_not_us))
}

report_sex <- function(sex_char_vector) {
  n_male <- sum(sex_char_vector == "Male")
  n_female <- sum(sex_char_vector == "Female")
  n_other <- sum(sex_char_vector == "Not listed:")
  if (n_other == 0) {
    return(str_c(n_male, "/", n_female))
  } else if (n_other > 1) {
    return(str_c(n_male, "/", n_female, "/", n_other))
  }
}

rt_demo <- aah_summary_all |>
  summarize(N = n(),
            `Age (years)` = report_mean_sd(age),
            `Education (years)`= report_mean_sd(education),
            `Sex (M/F)` = report_sex(sex),
            EHI = report_mean_sd(ehi_total),
  )

rt_demo |> pretty_table() |> tab_header(title = "Demographics", subtitle = "Summary")
```
<br>
```{r country}
aah_summary_all |>
  group_by(country) |>
  summarize(n = n()) |>
  rename(Country = country) |> 
  arrange(-n) |>
  pretty_table()
```
<br>
```{r race}
aah_summary_all |>
  group_by(race) |>
  summarize(n = n()) |>
  rename(Race = race) |> 
  arrange(-n) |>
  pretty_table()
```
<br>
```{r ethnicity}
aah_summary_all |>
  group_by(hispanic_ethnicity) |>
  summarize(n = n()) |>
  rename(`Hispanic ethnicity` = hispanic_ethnicity) |> 
  arrange(-n) |>
  pretty_table()
```
<br>
```{r task_experience}
task_experience <- aah_summary_all |>
  group_by(task_experience_response, task_experience_other_response) |>
  summarize(n = n()) |>
  rename(`Have you done this task before?` = task_experience_response,
         Explanation = task_experience_other_response) |> 
  arrange(-n)
task_experience |> pretty_table()
```
<br>

### Exclusions
```{r exclusions}
## TODO: Calculate any exclusions not based on task data
##   (Exclusions based on task data are specified in:
##    1_process.Rmd, calling load_process.R/summarize_ind())
##       Responded "go" almost every time (78/80 or more)?
##       Accuracy at 60% or lower on any main block?
##       Median RT over 1500 or under 200?
##       Took longer than 45 minutes to do the task?
## Exclusions not based on task data:
##   Demographics exclusions that slipped through pre-screener:
##     Country (non-us); Age (not between 18 and 40)
##   Failed "Have you done this task before"
##   (?) TODO: Failed interactive instructions
##    TODO: Have task data, but no EHI data.


##TODO: save long dataset with columns for all exclusion reasons.
##TODO: save as: proc_dir/aah_long.tsv

## Create long dataset with inclusions only
aah <- left_join(aah_task_all, aah_summary_all) |>
  filter(exclude == 0)
## TODO: save as: aah_noexclusions.tsv


## Create summary table with inclusions only
aah_summary <- aah_summary_all |> filter(exclude == 0)
```

### Demographics (Included)
<br>
```{r demographics_summary_included}
## Show one-row table with summary info
report_mean_sd <- function(numeric_vector) {
  return(str_c(
    round(mean(numeric_vector),2),
    " (", round(sd(numeric_vector), 2), ")"))
}

report_country <- function(country_char_vector) {
  n_us <- sum(country_char_vector == "US")
  n_not_us <- sum(country_char_vector != "US")
  return(str_c(n_us, "/", n_not_us))
}

report_sex <- function(sex_char_vector) {
  n_male <- sum(sex_char_vector == "Male")
  n_female <- sum(sex_char_vector == "Female")
  n_other <- sum(sex_char_vector == "Not listed:")
  if (n_other == 0) {
    return(str_c(n_male, "/", n_female))
  } else if (n_other > 1) {
    return(str_c(n_male, "/", n_female, "/", n_other))
  }
}

rt_demo <- aah_summary |>
  summarize(N = n(),
            `Age (years)` = report_mean_sd(age),
            `Education (years)`= report_mean_sd(education),
            `Sex (M/F)` = report_sex(sex),
            EHI = report_mean_sd(ehi_total),
  )

rt_demo |> pretty_table() |> tab_header(title = "Demographics", subtitle = "Summary")
```
<br>
```{r country_included}
aah_summary |>
  group_by(country) |>
  summarize(n = n()) |>
  rename(Country = country) |> 
  arrange(-n) |>
  pretty_table()
```
<br>
```{r race_included}
aah_summary |>
  group_by(race) |>
  summarize(n = n()) |>
  rename(Race = race) |> 
  arrange(-n) |>
  pretty_table()
```
<br>
```{r ethnicity_included}
aah_summary |>
  group_by(hispanic_ethnicity) |>
  summarize(n = n()) |>
  rename(`Hispanic ethnicity` = hispanic_ethnicity) |> 
  arrange(-n) |>
  pretty_table()
```
<br>

### Feedback
```{r feedback}
feedback <- aah_summary |>
  filter(open_ended_feedback_response != "NA") |> 
  group_by(open_ended_feedback_response, exclude) |>
  rename(`Open-ended feedback` = open_ended_feedback_response) |> 
  summarize()
feedback |> pretty_table()
```

### Blank (Collapse)

## Analyses {.tabset}

### Pilot analyses: Field x Level interaction {.tabset .tabset-pills .active}

In our pilot sample of right handers, do we see the typical field x level interaction? That is, do participants show a relative bias for global shapes in the left visual field (LVF)?
<br>

#### Reaction time
Reaction time is modeled as a linear effect of field and level, using data from every trial:
<br>
**lmer( rt ~ field + level + field:level + (1 | subject) )**
<br>
*Discussion question*: Should any variables not-of-interest be included as covariates? E.g., sex, target (circle/square), first block (z or slash), overall median rt (ms).
```{r rt_model}
## Make a linear model using data from every trial.
## Fixed effects: field, level (and their interaction)
## Random effects: subject.
## rt ~ field + level + field:level + (1 | subject)
rt_model <- lmer(rt ~ field:level + field + level + (1 | subject), data = aah)

## Create emmeans model object, and manually cache it.
#rt_emm <- emmeans(rt_model, ~ field*level)

## Manually cache model
#saveRDS(rt_emm, here("manual_cache", "rt_emm.rds"))

## Load cached model 
rt_emm <- readRDS(here("manual_cache", "rt_emm.rds"))
```
<!-- Test for field x level interaction, using the anova() function: is the interaction model's fit significantly different from the no-interaction model's fit? -->
<br>
```{r rt_interaction_anova}
## Use anova() on competing models to test 2-way interaction.
interaction_stats <-
  function(model_with_interaction,
           model_with_no_interaction) {
    return(anova(model_with_interaction, model_with_no_interaction))
  }

rt_model_no_interaction <- update(rt_model, . ~ . - field:level)
interaction_anova <- interaction_stats(rt_model, rt_model_no_interaction)
#interaction_anova
interaction_anova |>
  as_tibble() |>
  pretty_table() |> 
  tab_header(title = "Field by level interaction (RT)", 
             subtitle = "ANOVA: compare models with vs. without interaction term") 
```
<br>
```{r rt_interacion_aov}
## Use aov to test 2-way interaction with a traditional F-test.
rt_aov <- aov(rt ~ field + level + field:level, data = aah)
rt_aov_summary <- summary(rt_aov)
rt_aov_summary |> (\(.) .[[1]])() |> tidy() |> pretty_table() |>
  tab_header(title = "Field by level interaction (RT)",
             subtitle = "Old-school F-test")
```
<br>
<!-- Test for field x level interaction, using emmeans() - is the model's interaction effect estimate significantly different from zero? -->
```{r rt_interaction_emm}
## Use emmeans() to test 2-way interaction.
rt_interaction_emm <- rt_emm |>
  contrast(interaction = c("consec")) |>
  summary(infer = T)
#rt_interaction_emm

rt_interaction_emm |>
  as_tibble() |>
  pretty_table() |>
  tab_header(title = "Field by level interaction (RT)",
             subtitle = "Compare effect estimate to zero with emmeans()") |>
  tab_footnote(footnote = "A negative number means global bias is stronger in LVF",
               locations = cells_column_labels(columns = estimate)) |>
  tab_footnote(footnote = "Two-sided",
               locations = cells_column_labels(columns = p.value)) |>
  tab_footnote(footnote = "Confidence level: 95%",
               locations = cells_column_labels(columns = lower.CL)) |>
  tab_footnote(footnote = "Degrees-of-freedom method: kenward-roger",
               locations = cells_column_labels(columns = df))
```
<br>
```{r rt_field_bias}
rt_field_bias_emm <- rt_emm |>
  contrast("pairwise") |>
  summary(infer = T, adjust = "none", rows = c(3, 4))
#rt_field_bias_emm

rt_field_bias <- rt_field_bias_emm |>  
  as_tibble() |> 
  filter(contrast %in%
           c("LVF global - LVF local", "RVF global - RVF local"))

rt_field_bias |>
  pretty_table() |>
  tab_header(title = "Global bias by field (RT)") |>
  tab_footnote(footnote = "A negative number means global bias (faster RT for global)",
               locations = cells_column_labels(columns = estimate)) |>
  tab_footnote(footnote = "Confidence level: 95%",
               locations = cells_column_labels(columns = lower.CL)) |>
  tab_footnote(footnote = "Two-sided, uncorrected",
               locations = cells_column_labels(columns = p.value)) |>
  tab_footnote(footnote = "Degrees-of-freedom method: kenward-roger",
               locations = cells_column_labels(columns = df))
```
<br>
```{r rt_by_field_level}
rt_modelled <- summary(rt_emm, type = "response")
rt_modelled |>
  as_tibble() |>
  arrange(field) |>
  pretty_table() |>
  tab_header(title = "RT estimates by field and level (from model)") |>
  tab_footnote(footnote = "Confidence level: 95%",
               locations = cells_column_labels(columns = lower.CL)) |>
  tab_footnote(footnote = "Degrees-of-freedom method: kenward-roger",
               locations = cells_column_labels(columns = df))
```
<br>
```{r rt_descriptive}
rt_descriptive <- aah |>
  group_by(field, level) |>
  summarize(
    median = median(rt),
    mean = mean(rt),
    SE = sd(rt) / sqrt(length((rt)))
  )

rt_descriptive |>
  pretty_table() |>
  tab_header(title = "RT estimates by field and level (descriptive)")
```
<br>

#### Accuracy
Accuracy is modeled as a binomial effect of field and level, using data from every trial (correct/incorrect):
<br>
**glmer( correct ~ field + level + field:level + (1 | subject), family = "binomial" )**
<br>
*Discussion question*: Should any variables not-of-interest be included as covariates? E.g., sex, target (circle/square), first block (z or slash), overall median rt (ms).
```{r acc_model}
## Make a binomial logistic model using data from every trial.
## Fixed effects: field, level (and their interaction)
## Random effects: subject.
## correct ~ field + level + field:level + (1 | subject)
acc_model <- glmer(correct ~ field:level + field + level + (1 | subject),
                   data = aah,
                   family = "binomial")
#acc_model
## Create emmeans model object, and manually cache it.
#acc_emm <- emmeans(acc_model, ~ field*level)

## Manually cache model
#saveRDS(acc_emm, here("manual_cache", "acc_emm.rds"))

## Load cached model 
acc_emm <- readRDS(here("manual_cache", "acc_emm.rds"))
#acc_emm
#summary( acc_emm, type = "response")
```
<!-- Test for field x level interaction, using the anova() function: is the interaction model's fit significantly different from the no-interaction model's fit? -->
<br>
```{r acc_interaction_anova}
## Use anova() to test 2-way interaction effect.
interaction_stats <-
  function(model_with_interaction,
           model_with_no_interaction) {
    return(anova(model_with_interaction, model_with_no_interaction))
  }

acc_model_no_interaction <- update(acc_model, . ~ . - field:level)
interaction_anova <- interaction_stats(acc_model, acc_model_no_interaction)
#interaction_anova
interaction_anova |>
  as_tibble() |>
  pretty_table() |> 
  tab_header(title = "Field by level interaction (Accuracy)", 
             subtitle = "ANOVA: compare models with vs. without interaction term") 
```
<br>
<!-- Test for field x level interaction, using emmeans() - is the model's interaction effect estimate significantly different from zero? -->
```{r acc_interaction_emm}
## Is there an interaction of field x level?
## Use an emmeans contrast
acc_interaction_emm <- acc_emm |>
  contrast(interaction = c("consec")) |>
  summary(infer = T, type = "response")
#acc_interaction_emm

acc_interaction_emm |>
  as_tibble() |>
  pretty_table() |>
  tab_header(title = "Field by level interaction (Accuracy)",
             subtitle = "Compare effect estimate to zero with emmeans()") |>
  tab_footnote(footnote = "Backtransformed to odds ratio from log odds ratio; tests are performed on log odds ratio scale.",
               locations = cells_column_labels(columns = odds.ratio)) |>
  tab_footnote(footnote = "I don't understand why df is 'Inf' here, but I think it is expected when emmeans does logistic regressoin. See emmeans FAQ: https://cran.r-project.org/web/packages/emmeans/vignettes/FAQs.html#asymp.",
               locations = cells_column_labels(columns = df)) |>
  tab_footnote(footnote = "Confidence level: 95%",
               locations = cells_column_labels(columns = asymp.LCL)) |>
  tab_footnote(footnote = "Two-sided",
               locations = cells_column_labels(columns = p.value))
```
<br>
```{r acc_field_bias}
acc_field_bias_emm <- acc_emm |>
  contrast("pairwise") |>
  summary(infer = T, adjust = "none", type = "response")
#acc_field_bias_emm

acc_field_bias <- acc_field_bias_emm |>
  as_tibble() |>
  filter(contrast %in%
           c("LVF global / LVF local", "RVF global / RVF local"))
#acc_field_bias

acc_field_bias |>
  pretty_table() |>
  tab_header(title = "Global bias by field (Accuracy)") |>
  tab_footnote(footnote =  "Backtransformed to odds ratio from log odds ratio (tests are performed on log odds ratio scale). A ratio > 1 means global bias (more correct responses for global).",
               locations = cells_column_labels(columns = odds.ratio)) |>
  tab_footnote(footnote = "Confidence level: 95%",
               locations = cells_column_labels(columns = asymp.LCL)) |>
  tab_footnote(footnote = "Two-sided, uncorrected",
               locations = cells_column_labels(columns = p.value))
```
<br>
```{r acc_by_field_level}
acc_modelled <- summary(acc_emm, type = "response")
# acc_modelled
acc_modelled |>
  as_tibble() |> 
  arrange(field) |> 
  pretty_table() |>
  tab_header(title = "Accuracy estimates by field and level (from model)") |>
  tab_footnote(footnote = "Back-transformed to probability (% correct) from logit scale",
               locations = cells_column_labels(columns = prob)) |>
  tab_footnote(footnote = "Confidence level: 95%",
               locations = cells_column_labels(columns = asymp.LCL))
```
<br>
```{r acc_descriptive}
acc_descriptive <- response_counts_condition <- aah |>
      group_by(level, field, subject) |>
      summarize(
        total_responses = n(),
        n_present_resp = sum(correct),
        n_absent_resp = total_responses - n_present_resp,
        n_correct = sum(correct),
        percent_correct = 100 * (n_correct / total_responses)
      ) |> 
      group_by(field, level) |> 
      summarize(mean_subject_percent_correct = mean(percent_correct))
#acc_descriptive
    
acc_descriptive |>
  pretty_table() |>
  tab_header(title = "Accuracy estimates by field and level (descriptive)")
```
<br>

### Field x Level x Handedness
Once we collect data on lefties, we will test whether LVF-global bias is reduced or reversed with left handedness.
```{r analyze_main_rt}
## Reaction time analyses.
## Linear model using data from every trial.
## (1) Binary handedness. 
## rt ~ target*field*level*handedness

## (2) Continuous handedness

## As a sanity check, do parallel analyses with summary rt data instead of trial-level data.
```

```{r analyse_main_acc}
```

<!-- ## Visualize individual results -->
```{r visualize_individual_rt}
## Visualize per-trial RT data (make absent one color, present another)

```

<!-- ## Visualize group results -->
```{r}
## ## Visualize RT data by condition
```

```{r visualize_group_acc}
## Visualize accuracy data by condition
```

### Blank (Collapse)
